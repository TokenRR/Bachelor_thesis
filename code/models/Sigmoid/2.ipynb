{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import PIL\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size1 = 498\n",
    "crop_size2 = 300\n",
    "upscale_factor = 3\n",
    "input_size1 = crop_size1 // upscale_factor\n",
    "input_size2 = crop_size2  // upscale_factor\n",
    "path = \"D:\\\\KPI\\\\Bachelor_thesis\\\\code\\\\data\\\\images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = image_dataset_from_directory(path,\n",
    "                                         image_size=(crop_size1, crop_size2),\n",
    "                                         validation_split=0.2,\n",
    "                                         subset='training',\n",
    "                                         seed=1337,\n",
    "                                         batch_size = 16,\n",
    "                                         label_mode=None)\n",
    "\n",
    "valid_set = image_dataset_from_directory(path,\n",
    "                                         image_size=(crop_size1, crop_size2),\n",
    "                                         validation_split=0.2,\n",
    "                                         subset='validation',\n",
    "                                         seed=1337,\n",
    "                                         batch_size = 16,\n",
    "                                         label_mode=None)\n",
    "\n",
    "def rescaling(input_image):\n",
    "    input_image = input_image / 255.0\n",
    "    return input_image\n",
    "    \n",
    "train_set = train_set.map(rescaling)\n",
    "valid_set = valid_set.map(rescaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_set.take(1):\n",
    "#     for img in batch:\n",
    "#         display(array_to_img(img)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(path,'val')       \n",
    "\n",
    "test_img_paths = sorted([os.path.join(test_path,img_name)\n",
    "                        for img_name in os.listdir(test_path)\n",
    "                        if img_name.endswith('.png' or 'jpg')])\n",
    "    \n",
    "shape_prior = list(train_set.as_numpy_iterator())\n",
    "\n",
    "def process_input(input, size1, size2):\n",
    "    input = tf.image.rgb_to_yuv(input)\n",
    "    last_axis = len(input.shape) -1\n",
    "    y, u, v = tf.split(input, 3, axis=last_axis)\n",
    "    return tf.image.resize(y, [size1, size2], method=\"area\")\n",
    "\n",
    "def process_target(input):\n",
    "    input = tf.image.rgb_to_yuv(input)\n",
    "    last_axis = len(input.shape) -1\n",
    "    y, u, v = tf.split(input, 3, axis=last_axis)\n",
    "    return y\n",
    "\n",
    "train_set = train_set.map(lambda x: (process_input(x, input_size1, input_size2),process_target(x)))\n",
    "\n",
    "#train_set = train_set.prefetch(buffer_size=32)\n",
    "\n",
    "shape_after = list(train_set.as_numpy_iterator())\n",
    "\n",
    "valid_set = valid_set.map(lambda x: (process_input(x, input_size1, input_size2),process_target(x)))\n",
    "\n",
    "#valid_set = valid_set.prefetch(buffer_size=32)\n",
    "\n",
    "channels = shape_after[0][0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_set.take(1):\n",
    "#     for img in batch[0]:\n",
    "#         display(array_to_img(img))\n",
    "#     for img in batch[1]:\n",
    "#         display(array_to_img(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(channels, upscale_factor):\n",
    "    inputs = keras.Input(shape=(None, None, channels))\n",
    "    X = Conv2D(64, 5, padding='same', activation='relu', kernel_initializer='Orthogonal')(inputs)\n",
    "    X = Conv2D(64, 3, padding='same', activation='relu', kernel_initializer='Orthogonal')(X)\n",
    "    X = Conv2D(32, 3, padding='same', activation='relu', kernel_initializer='Orthogonal')(X)\n",
    "    X = Conv2D(channels * (upscale_factor**2), 3, padding='same', activation='sigmoid', kernel_initializer='Orthogonal')(X)\n",
    "    outputs = tf.nn.depth_to_space(X, upscale_factor)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss',patience=10, min_delta=0.0001)\n",
    "model = Model(channels, upscale_factor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_set, epochs=40, callbacks=[early_stopping], validation_data = valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('Y_Model_SGD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(img, prefix, title):\n",
    "    \"\"\"Plot the result with zoom-in area.\"\"\"\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array.astype(\"float32\") / 255.0\n",
    "\n",
    "    # Create a new figure with a default 111 subplot.\n",
    "    figure, parent = plt.subplots()\n",
    "    parent.imshow(img_array[::-1], origin=\"lower\")     # The reason why we want to\n",
    "                                                       # plot the figure in reverse\n",
    "    plt.title(title)                                   # here is because when we use\n",
    "    # zoom-factor: 2.0, location: upper-left           # img_to_array, the height and\n",
    "    inset = zoomed_inset_axes(parent, 2, loc='upper left') # width locations get inverted.\n",
    "    inset.imshow(img_array[::-1], origin=\"lower\")\n",
    "\n",
    "    # Specify the limits.\n",
    "    x1, x2, y1, y2 = 200, 300, 150, 250\n",
    "    # Apply the x-limits.\n",
    "    inset.set_xlim(x1, x2)\n",
    "    # Apply the y-limits.\n",
    "    inset.set_ylim(y1, y2)\n",
    "\n",
    "    plt.yticks(visible=False)\n",
    "    plt.xticks(visible=False)\n",
    "\n",
    "    # Make the line.\n",
    "    mark_inset(parent, inset, loc1=1, loc2=3, fc=\"none\", ec=\"blue\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bicubic_psnr = 0.0\n",
    "total_test_psnr = 0.0\n",
    "counter = 0\n",
    "\n",
    "for index, _ in enumerate(test_img_paths):\n",
    "    \n",
    "    image = PIL.Image.open(_)\n",
    "    \n",
    "    test = img_to_array(image)\n",
    "    \n",
    "    if test.shape[2] == 3:\n",
    "        \n",
    "        counter += 1\n",
    "     \n",
    "        #plot_results(image, index, index)\n",
    "        \n",
    "        lowres = image.resize((image.size[0] // upscale_factor,\n",
    "                               image.size[1] // upscale_factor),\n",
    "                              PIL.Image.BICUBIC)\n",
    "        \n",
    "        ycbcr = lowres.convert(\"YCbCr\")         # Here, we converted the image to \n",
    "        y, cb, cr = ycbcr.split()               # YCbCr because we need the y-channel\n",
    "        y = img_to_array(y)                     # for our model. The we did not convert\n",
    "        y = y.astype(\"float32\") / 255.0         # it to YUV is because we can't in PIL\n",
    "                                                # and Y in YCbCr is the same as in YUV.\n",
    "        input = y.reshape(1, y.shape[0], y.shape[1], y.shape[2])\n",
    "        \n",
    "        \"\"\"\n",
    "        In the previous line, we have to reshape our y channel because the input\n",
    "        of the model must be: (Batch, Height, Width, Channels).\n",
    "        \"\"\"\n",
    "        \n",
    "        output = model.predict(input)\n",
    "        \n",
    "        output = output[0]\n",
    "        \n",
    "        output *= 255.0\n",
    "        \n",
    "        # Restore the image in RGB color space.\n",
    "        \n",
    "        output = output.clip(0, 255)\n",
    "        \n",
    "        output = output.reshape((output.shape[0], output.shape[1]))\n",
    "        \n",
    "        output = PIL.Image.fromarray(np.uint8(output))\n",
    "        \n",
    "        output = output.resize(image.size, PIL.Image.Resampling.NEAREST)\n",
    "        \n",
    "        cb = cb.resize(output.size, PIL.Image.Resampling.BICUBIC)\n",
    "        \n",
    "        cr = cr.resize(output.size, PIL.Image.Resampling.BICUBIC)\n",
    "        \n",
    "        output = PIL.Image.merge(\"YCbCr\", (output, cb, cr))\n",
    "        \n",
    "        output = output.convert(\"RGB\")\n",
    "         \n",
    "        lowres = lowres.resize(output.size, PIL.Image.Resampling.BICUBIC)\n",
    "        \n",
    "        #plot_results(output, index, index)\n",
    "        \n",
    "        #plot_results(lowres, index, index)\n",
    "        \n",
    "        lowres_arr = img_to_array(lowres)\n",
    "        image_arr = img_to_array(image)\n",
    "        output_arr = img_to_array(output)\n",
    "        bicubic_psnr = tf.image.psnr(lowres_arr, image_arr, max_val=255)\n",
    "        test_psnr = tf.image.psnr(output_arr, image_arr, max_val=255)\n",
    "    \n",
    "        total_bicubic_psnr += bicubic_psnr\n",
    "        total_test_psnr += test_psnr\n",
    "    \n",
    "        #print(\"PSNR of low resolution image and high resolution image is %.4f\" % bicubic_psnr)\n",
    "        #print(\"PSNR of predict and high resolution is %.4f\" % test_psnr)\n",
    "    \n",
    "    \n",
    "print(\"Avg. PSNR of lowres images is %.4f\" % (total_bicubic_psnr / counter))\n",
    "print(\"Avg. PSNR of reconstructions is %.4f\" % (total_test_psnr / counter))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
